---
title: "Lecture 10 - Key"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(knitr)
```


## The Bootstrap
Our final section takes a slight diversion from the textbook to focus on another important (re)sampling technique known as the bootstrap.
\vfill

Situation: Let $y_1, y_2, \dots, y_n$ be a SRS of size $n$ taken from a distribution $F$ that is unknown. Let $\theta$ be a parameter of interest associated with this distribution and let $\hat{\theta}= S(y_1, y_2, \dots, y_n)$ be a statistic used to estimate $\theta$. The notation $S(y_1, y_2, \dots, y_n)$ denotes a statistic based on the data $y_1, y_2, \dots, y_n$.
\vfill

- Ex. The sample mean $\bar{y} = \hat{\theta} = S(y_1, y_2, \dots, y_n)$ is a statistic used to estimate the true mean. 
\vfill

Similar to our other sampling procedures, with the point estimate $\hat{\theta}$ we are interested in determining:
 
1. the 
\vfill
 
2. the 
\vfill
 
3. the 
\vfill


Bootstrap methods are computer intensive methods for estimating these quantities using bootstrap samples.
\vfill

 A bootstrap sample is a SRS of size $n$ taken with replacement from the original data $y_1, y_2, \dots, y_n$.
 \vfill
 
We denote a bootstrap sample as $y^*_1, y^*_2, \dots, y^*_n$ which consists of 
\vfill

A bootstrap sample replication of $\hat{\theta}$, denoted $\hat{\theta}^*$, is the value of $\hat{\theta}$ evaluated 
\vfill

The bootstrap algorithm requires that a large number (B) of bootstrap sample be taken. The bootstrap sample replication $\hat{\theta}^*$ is then calculated for each of the B bootstrap samples. 
\vfill

Example. Consider six data points that correspond to the inches of snowfall on your scheduled exam dates: \{$y_1 = 9, y_2 = 4, y_3 =13, y_4 =5, y_5 =6, y_6=8\}$.

\vfill

\newpage

Using the snowfall dataset, write R pseudocode for taking bootstrap samples from the snowfall dataset.
\vfill
\vfill

```{r, echo = F}
snowfall <- c(9,4,13,5,6,8)
kable(t(replicate(20, sample(snowfall, replace = T))), col.names = paste('sample',c(1:6))) 
```

\newpage

### Bootstrap Estimate of Standard Error

The bootstrap estimate of the standard error of $\hat{\theta}$ is 
\begin{equation*}
SE_{b}(\hat{\theta}) = \sqrt{\frac{\sum_{b=1}^B[\hat{\beta}^*(b) - \hat{\bar{\theta}}^*]^2}{B-1}},
\end{equation*}
where $\hat{\bar{\theta}}^* = \sum_{b=1}^B \hat{\theta}^*(b) \ B$ is the sample mean of the $B$ bootstrap replications. We have actually done something very similar. 
\vfill

Note that the previous equation for $SE_B(\hat{\theta})$ is
\vfill

Under many circumstances, as the sample size $n$ increases, the sampling distribution of $\hat{\theta}$ becomes more normally distributed. Under this assumption, an approximate t-based bootstrap confidence interval can be generated using $SE_B(\hat{\theta})$ and a t-distribution:
\vfill
\vfill


### Bootstrap Estimate of Bias

The bias of $\hat{\theta} = S(Y_1, Y_2, \dots, Y_N)$ as an estimator of $\theta$ is defined as:
\begin{equation*}
bias(\hat{\theta}) = E[\hat{\theta}] - \theta.
\end{equation*}
\vfill

The bootstrap estimate of the bias of $\hat{\theta}$ as an estimate of $\theta$ is calculated by replacing the distribution $F$ with the empirical distribution function $\hat{F}$. In other words the expectation (with respect to F) is unknown, but can be estimated using the empirical CDF $\hat{F}$ using the bootstrap samples. This yields
\begin{equation*}
\hat{bias}_b(\hat{\theta}) = \hat{\bar{\theta}}^* - \hat{\theta}.
\end{equation*}
\vfill

Then, the bias-corrected estimate of $\theta$ is 
\begin{equation*}
\tilde{\theta}_B = \hat{\theta} - \hat{bias}_B(\hat{\theta}) = 2\hat{\theta} - \hat{\bar{\theta}}^*.
\end{equation*}
\vfill

One suggestion is to center confidence intervals at $\tilde{\theta}$ such that bias corrected t-based confidence intervals can be expressed as $\tilde{\theta}_B \pm t^* SE_B(\hat{\theta})$.
\vfill

\newpage

### Bootstrap Confidence Intervals
There are a few options for generating confidence intervals from bootstrap replications.
\vfill

The first option uses the normal approximation. An approximate $100(1-\alpha)\%$ confidence interval for $\theta$ is 
	\begin{equation*}
	\hat{\theta} \pm t^* SE_B(\hat{\theta}) \hspace{1.5cm} \text{or} \hspace{1.5cm} \hat{\theta} \pm z^* SE_B(\hat{\theta}),
	\end{equation*}
	where $t^*$ is an $\alpha/2$ critical value from a $t$-distribution with $n-1$ degrees of freedom and $z^*$ is the $\alpha/2$ critical value from a normal distribution.
\vfill

Recall, the confidence intervals can also be centered at the bias corrected point estimate $\tilde{\theta}$.
\vfill

For an approximate $95\%$ confidence interval for $\theta$ to be useful, it is expected that $95\%$ of the confidence intervals from this method would contain $\theta$. The same principle holds for other confidence levels.
\vfill

If the sample size is not large enough and the distribution sampled from is highly skewed (or not close to a normal distribution), 
\vfill

Another option for calculating bootstrap based confidence intervals uses the percentiles from the bootstrap samples.
\vfill

If the sample size is 
\vfill

The simplest alternative is to use percentiles from the $B$ bootstrap replications.
\vfill

The approximate bootstrap percentile-based confidence interval for $\theta$ is 
\begin{equation*}
(\hat{\theta}_L^* , \hat{\theta}_U^*)
\end{equation*}
where $\hat{\theta}_L^*$ and $\hat{\theta}_U^*$ are the lower $\alpha/2$ and upper $(1-\alpha/2)$ percentiles of the $B$ bootstrap replications respectively.
\vfill

Practically to find $\hat{\theta}_L^*$ and $\hat{\theta}_U^*$ you:

1. Order 
\vfill

2. Calculate 
\vfill

3. Find 
\vfill

4. The 
\vfill

Note the function `quantile(theta.star,probs=c(alpha/2,(1-alpha/2))` in R will return $\hat{\theta}_L$ and $\hat{\theta}_U$.

\vfill
Now continue with the snowfall dataset to create confidence intervals using the normal approach (t-dist) and the quantile-based approach.
